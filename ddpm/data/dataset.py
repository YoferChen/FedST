import torch.utils.data as data
from torchvision import transforms
from PIL import Image
import os
import torch
import numpy as np

from .util.mask import (bbox2mask, brush_stroke_mask, get_irregular_mask, random_bbox, random_cropping_bbox)

IMG_EXTENSIONS = [
    '.jpg', '.JPG', '.jpeg', '.JPEG',
    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',
]


def is_image_file(filename):
    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)


def make_dataset(dir):
    if os.path.isfile(dir):
        images = [i for i in np.genfromtxt(dir, dtype=np.str, encoding='utf-8')]
    else:
        images = []
        assert os.path.isdir(dir), '%s is not a valid directory' % dir
        for root, _, fnames in sorted(os.walk(dir)):
            for fname in sorted(fnames):
                if is_image_file(fname):
                    path = os.path.join(root, fname)
                    images.append(path)

    return images


def make_labels(file):
    with open(file, 'r') as file:
        labels = file.readlines()
        labels = [int(label.strip()) for label in labels]

    return labels


def pil_loader(path, input_nc=1):
    if input_nc == 3:
        img = Image.open(path).convert('RGB')
    else:
        img = Image.open(path).convert('L')
    return img


class InpaintDataset(data.Dataset):
    def __init__(self, data_root, mask_config={}, data_len=-1, image_size=[256, 256], loader=pil_loader):
        imgs = make_dataset(data_root)
        if data_len > 0:
            self.imgs = imgs[:int(data_len)]
        else:
            self.imgs = imgs
        self.tfs = transforms.Compose([
            transforms.Resize((image_size[0], image_size[1])),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        self.loader = loader
        self.mask_config = mask_config
        self.mask_mode = self.mask_config['mask_mode']
        self.image_size = image_size

    def __getitem__(self, index):
        ret = {}
        path = self.imgs[index]
        img = self.tfs(self.loader(path))
        mask = self.get_mask()
        cond_image = img * (1. - mask) + mask * torch.randn_like(img)
        mask_img = img * (1. - mask) + mask

        ret['gt_image'] = img
        ret['cond_image'] = cond_image
        ret['mask_image'] = mask_img
        ret['mask'] = mask
        ret['path'] = path.rsplit("/")[-1].rsplit("\\")[-1]
        return ret

    def __len__(self):
        return len(self.imgs)

    def get_mask(self):
        if self.mask_mode == 'bbox':
            mask = bbox2mask(self.image_size, random_bbox())
        elif self.mask_mode == 'center':
            h, w = self.image_size
            mask = bbox2mask(self.image_size, (h // 4, w // 4, h // 2, w // 2))
        elif self.mask_mode == 'irregular':
            mask = get_irregular_mask(self.image_size)
        elif self.mask_mode == 'free_form':
            mask = brush_stroke_mask(self.image_size)
        elif self.mask_mode == 'hybrid':
            regular_mask = bbox2mask(self.image_size, random_bbox())
            irregular_mask = brush_stroke_mask(self.image_size, )
            mask = regular_mask | irregular_mask
        elif self.mask_mode == 'file':
            pass
        else:
            raise NotImplementedError(
                f'Mask mode {self.mask_mode} has not been implemented.')
        return torch.from_numpy(mask).permute(2, 0, 1)


class UncroppingDataset(data.Dataset):
    def __init__(self, data_root, mask_config={}, data_len=-1, image_size=[256, 256], loader=pil_loader):
        imgs = make_dataset(data_root)
        if data_len > 0:
            self.imgs = imgs[:int(data_len)]
        else:
            self.imgs = imgs
        self.tfs = transforms.Compose([
            transforms.Resize((image_size[0], image_size[1])),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        self.loader = loader
        self.mask_config = mask_config
        self.mask_mode = self.mask_config['mask_mode']
        self.image_size = image_size

    def __getitem__(self, index):
        ret = {}
        path = self.imgs[index]
        img = self.tfs(self.loader(path))
        mask = self.get_mask()
        cond_image = img * (1. - mask) + mask * torch.randn_like(img)
        mask_img = img * (1. - mask) + mask

        ret['gt_image'] = img
        ret['cond_image'] = cond_image
        ret['mask_image'] = mask_img
        ret['mask'] = mask
        ret['path'] = path.rsplit("/")[-1].rsplit("\\")[-1]
        return ret

    def __len__(self):
        return len(self.imgs)

    def get_mask(self):
        if self.mask_mode == 'manual':
            mask = bbox2mask(self.image_size, self.mask_config['shape'])
        elif self.mask_mode == 'fourdirection' or self.mask_mode == 'onedirection':
            mask = bbox2mask(self.image_size, random_cropping_bbox(mask_mode=self.mask_mode))
        elif self.mask_mode == 'hybrid':
            if np.random.randint(0, 2) < 1:
                mask = bbox2mask(self.image_size, random_cropping_bbox(mask_mode='onedirection'))
            else:
                mask = bbox2mask(self.image_size, random_cropping_bbox(mask_mode='fourdirection'))
        elif self.mask_mode == 'file':
            pass
        else:
            raise NotImplementedError(
                f'Mask mode {self.mask_mode} has not been implemented.')
        return torch.from_numpy(mask).permute(2, 0, 1)


class Medical_MaterialDataset(data.Dataset):
    def __init__(self, data_root, data_flist, data_len=-1, data_client="0", model_client="0", image_size=[256, 256],
                 loader=pil_loader):
        self.data_root = data_root
        flist = make_dataset(data_flist)
        if data_len > 0:
            self.flist = flist[:int(data_len)]
        else:
            self.flist = flist
        self.tfs = transforms.Compose([
            # transforms.Resize((image_size[0], image_size[1])),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])
        self.loader = loader
        self.image_size = image_size
        self.client = data_client
        self.model_class = model_client

    def __getitem__(self, index):
        ret = {}
        file_name = self.flist[index]

        img = self.loader('{}/{}/{}'.format(self.data_root, 'train/real_image/' + self.client, file_name), input_nc=3)
        label = self.loader(
            '{}/{}/{}'.format(self.data_root, 'train/real_label/' + self.client, file_name.replace("bmp", "png")),
            input_nc=3)

        img = img.resize((self.image_size[0], self.image_size[1]))
        label = np.array(label.resize((self.image_size[0], self.image_size[1]), resample=Image.NEAREST))

        img = self.tfs(img)

        if np.max(label) > 125:
            cond_image = self.tfs(label)
        else:
            cond_image = self.tfs(label * 255)

        ret['gt_image'] = img
        ret['cond_image'] = cond_image
        ret['path'] = file_name
        ret['class'] = int(self.client)
        ret['model_class'] = int(self.model_class)
        return ret

    def __len__(self):
        return len(self.flist)


class DP590Dataset(data.Dataset):
    def __init__(self, data_root, data_flist, data_len=-1, data_client="0", model_client="0", image_size=[512, 512],
                 loader=pil_loader):
        self.data_root = data_root
        flist = make_dataset(data_flist)
        if data_len > 0:
            self.flist = flist[:int(data_len)]
        else:
            self.flist = flist
        self.tfs = transforms.Compose([
            # transforms.Resize((image_size[0], image_size[1])),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])
        self.loader = loader
        self.image_size = image_size
        self.client = data_client
        self.model_class = model_client

    def __getitem__(self, index):
        ret = {}
        file_name = self.flist[index]

        img = self.loader('{}/{}/{}'.format(self.data_root, 'train/real_image/' + self.client, file_name), input_nc=3)
        label = self.loader(
            '{}/{}/{}'.format(self.data_root, 'train/real_label/' + self.client, file_name.replace("bmp", "png")),
            input_nc=3)

        img = img.resize((self.image_size[0], self.image_size[1]))
        label = np.array(label.resize((self.image_size[0], self.image_size[1]), resample=Image.NEAREST))
        # label = np.zeros_like(label, dtype=np.uint8)  # 攻击测试使用

        img = self.tfs(img)

        if np.max(label) > 125:
            cond_image = self.tfs(label)
        else:
            cond_image = self.tfs(label * 255)

        ret['gt_image'] = img
        ret['cond_image'] = cond_image
        ret['path'] = file_name
        ret['class'] = int(self.client)
        ret['model_class'] = int(self.model_class)
        return ret

    def __len__(self):
        return len(self.flist)


class FaceDataset(data.Dataset):
    def __init__(self, data_root, data_flist, data_len=-1, data_client="0", model_client="0", image_size=[256, 256],
                 loader=pil_loader):
        self.data_root = data_root
        flist = make_dataset(data_flist)
        if data_len > 0:
            self.flist = flist[:int(data_len)]
        else:
            self.flist = flist
        self.tfs = transforms.Compose([
            # transforms.Resize((image_size[0], image_size[1])),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])
        self.loader = loader
        self.image_size = image_size
        self.client = data_client
        self.model_class = model_client

    def __getitem__(self, index):
        ret = {}
        file_name = self.flist[index]

        img = self.loader('{}/{}/{}'.format(self.data_root, 'train/real_image/' + self.client, file_name), input_nc=3)
        label = self.loader('{}/{}/{}'.format(self.data_root, 'train/real_label/' + self.client, file_name), input_nc=3)

        img = img.resize((self.image_size[0], self.image_size[1]))
        label = np.array(label.resize((self.image_size[0], self.image_size[1]), resample=Image.NEAREST)).astype(
            np.float)
        label = (label * 255 / 18).astype(np.uint8)

        img = self.tfs(img)
        cond_image = self.tfs(label).type(torch.float32)

        ret['gt_image'] = img
        ret['cond_image'] = cond_image
        ret['path'] = file_name
        ret['class'] = int(self.client)
        ret['model_class'] = int(self.model_class)
        return ret

    def __len__(self):
        return len(self.flist)


class AAFDataset(data.Dataset):
    def __init__(self, data_root, data_flist, data_len=-1, data_client="0", model_client="0", image_size=[256, 256],
                 loader=pil_loader):
        self.data_root = data_root
        flist = make_dataset(data_flist)
        if data_len > 0:
            self.flist = flist[:int(data_len)]
        else:
            self.flist = flist
        self.tfs = transforms.Compose([
            # transforms.Resize((image_size[0], image_size[1])),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])
        self.loader = loader
        self.image_size = image_size
        self.client = data_client
        self.model_class = model_client

    def __getitem__(self, index):
        ret = {}
        file_name = self.flist[index]

        img = self.loader('{}/{}/{}'.format(self.data_root, 'train/real_image/' + self.client, file_name), input_nc=3)
        label = self.loader('{}/{}/{}'.format(self.data_root, 'train/real_label/' + self.client, file_name), input_nc=3)

        img = img.resize((self.image_size[0], self.image_size[1]))
        label = np.array(label.resize((self.image_size[0], self.image_size[1]), resample=Image.NEAREST)).astype(
            np.float)
        label = (label * 255 / 19).astype(np.uint8)  # 19个类别+1个背景

        img = self.tfs(img)
        cond_image = self.tfs(label).type(torch.float32)

        ret['gt_image'] = img
        ret['cond_image'] = cond_image
        ret['path'] = file_name
        ret['class'] = int(self.client)
        ret['model_class'] = int(self.model_class)
        return ret

    def __len__(self):
        return len(self.flist)


class AAFNewDataset(data.Dataset):
    def __init__(self, data_root, data_flist, data_len=-1, data_client="0", model_client="0", image_size=[256, 256],
                 loader=pil_loader):
        self.data_root = data_root
        flist = make_dataset(data_flist)
        if data_len > 0:
            self.flist = flist[:int(data_len)]
        else:
            self.flist = flist
        self.tfs = transforms.Compose([
            # transforms.Resize((image_size[0], image_size[1])),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])
        self.loader = loader
        self.image_size = image_size
        self.client = data_client
        self.model_class = model_client

    def __getitem__(self, index):
        ret = {}
        file_name = self.flist[index]

        img = self.loader('{}/{}/{}'.format(self.data_root, 'train/real_image/' + self.client, file_name), input_nc=3)
        label = self.loader('{}/{}/{}'.format(self.data_root, 'train/real_label/' + self.client, file_name), input_nc=3)

        img = img.resize((self.image_size[0], self.image_size[1]))
        label = np.array(label.resize((self.image_size[0], self.image_size[1]), resample=Image.NEAREST)).astype(
            np.float)
        label = (label * 255 / 18).astype(np.uint8)  # 18个类别+1个背景
        # label = np.zeros_like(label, dtype=np.uint8)  # 攻击测试使用
        # label = np.ones_like(label, dtype=np.uint8)*255  # 攻击测试使用

        img = self.tfs(img)
        cond_image = self.tfs(label).type(torch.float32)

        ret['gt_image'] = img
        ret['cond_image'] = cond_image
        ret['path'] = file_name
        ret['class'] = int(self.client)
        ret['model_class'] = int(self.model_class)
        return ret

    def __len__(self):
        return len(self.flist)


class CatDogDataset(data.Dataset):
    def __init__(self, data_root, data_flist, mask_config={}, data_len=-1, data_client="0", model_client="0",
                 image_size=[256, 256], loader=pil_loader):
        self.data_root = data_root
        flist = make_dataset(data_flist)
        if data_len > 0:
            self.flist = flist[:int(data_len)]
        else:
            self.flist = flist
        self.tfs = transforms.Compose([
            transforms.Resize((image_size[0], image_size[1])),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        self.loader = loader
        self.mask_config = mask_config
        self.mask_mode = self.mask_config['mask_mode']
        self.image_size = image_size
        self.client = data_client
        self.labels = make_labels(os.path.join(self.data_root, 'train/real_label/' + self.client, "label.txt"))
        # for test
        self.model_class = model_client
        self.test_labels = make_labels(
            os.path.join(self.data_root, 'train/real_label/' + self.model_class, "label.txt"))

    def __getitem__(self, index):
        ret = {}
        file_name = self.flist[index]
        path = os.path.join(self.data_root, 'train/real_image/' + self.client, file_name)
        img = self.tfs(self.loader(path, input_nc=3))
        mask = self.get_mask()
        cond_image = img * (1. - mask) + mask * torch.randn_like(img)
        mask_img = img * (1. - mask) + mask

        ret['gt_image'] = img
        ret['cond_image'] = cond_image
        ret['mask_image'] = mask_img
        ret['mask'] = mask
        ret['class'] = self.labels[index]
        ret['model_class'] = self.test_labels[index]
        ret['path'] = path.rsplit("/")[-1].rsplit("\\")[-1]
        return ret

    def __len__(self):
        return len(self.flist)

    def get_mask(self):
        if self.mask_mode == 'bbox':
            mask = bbox2mask(self.image_size, random_bbox())
        elif self.mask_mode == 'center':
            h, w = self.image_size
            mask = bbox2mask(self.image_size, (30, 30, 192, 192))  # (h//4, w//4, h//2, w//2)
        elif self.mask_mode == 'irregular':
            mask = get_irregular_mask(self.image_size)
        elif self.mask_mode == 'free_form':
            mask = brush_stroke_mask(self.image_size)
        elif self.mask_mode == 'hybrid':
            regular_mask = bbox2mask(self.image_size, random_bbox())
            irregular_mask = brush_stroke_mask(self.image_size, )
            mask = regular_mask | irregular_mask
        elif self.mask_mode == 'file':
            pass
        else:
            raise NotImplementedError(
                f'Mask mode {self.mask_mode} has not been implemented.')
        return torch.from_numpy(mask).permute(2, 0, 1)
