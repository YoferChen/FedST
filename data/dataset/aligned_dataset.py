from data.dataset.base_dataset import BaseDataset
from data.dataset.image_folder import make_dataset, is_image_file

import torchvision.transforms as tr
import torchvision.transforms.functional as F
import random
import os
from PIL import Image
import numpy as np
import pdb
import re
import torch
from skimage.io import imread
import matplotlib.pyplot as plt
from scipy import ndimage
from models.losses.losses import *
from random import choice
import json


class AlignedDataset(BaseDataset):
    @staticmethod
    def modify_commandline_options(parser):
        return parser

    def initialize(self, opt, dataroot=None, image_dir=None, label_dir=None, record_txt=None, transform=None,
                   is_aug=False, train_dataidxs=None, image_name=None, label_name=None, scale=1):
        assert not None in [dataroot, image_dir, label_dir], \
            'dataroot:%s \nimage_dirs:%s\nlabel_dir:%s' % (dataroot, image_dir, label_dir)

        self.opt = opt
        self.input_nc = opt.input_nc
        self.image_name = image_name
        self.label_name = label_name
        self.transform = tr.Compose([
            tr.ToTensor(),
            tr.Normalize([0.5], [0.5]),
        ])
        self.mix = True

        # './dataset/CHAOS_liver/train/real_image', './dataset/CHAOS_liver/train/real_label'
        image_folder = os.path.join(dataroot, image_dir)
        label_folder = os.path.join(dataroot, label_dir)

        if (train_dataidxs == None):
            if self.opt.client_id != -1:
                self.image_paths = sorted(make_dataset(image_folder, record_txt, client_id=self.opt.client_id))
                self.label_paths = sorted(make_dataset(label_folder, record_txt, client_id=self.opt.client_id))
            else:
                self.image_paths = sorted(make_dataset(image_folder, record_txt))
                self.label_paths = sorted(make_dataset(label_folder, record_txt))

        else:
            self.image_paths = sorted([i for i in sorted(np.array(image_name)[train_dataidxs]) if
                                       is_image_file(i) and (not i.startswith('.'))])
            self.label_paths = sorted([i for i in sorted(np.array(label_name)[train_dataidxs]) if
                                       is_image_file(i) and (not i.startswith('.'))])
            self.image_paths = [os.path.join(dataroot, image_dir, i) for i in self.image_paths]
            self.label_paths = [os.path.join(dataroot, label_dir, i) for i in self.label_paths]

        self.freq_list_clients = []  # 每个client取八分之一的数据提取振幅谱信息进入bank中，每一个client保存一个列表。
        image_paths_all = sorted(make_dataset(image_folder))
        image_paths_length = len(image_paths_all)
        client_length = image_paths_length // self.opt.client_num_in_total
        self.client_data_0 = image_paths_all[0: client_length]
        self.client_data_1 = image_paths_all[client_length: 2 * client_length]
        for i in range(self.opt.client_num_in_total):
            freq_list = image_paths_all[i * client_length: (i + 1) * client_length]
            length = len(freq_list)
            freq_list = random.sample(freq_list, int(length / 8))
            self.freq_list_clients.append(freq_list)

        self.fake_dict = {}
        # Get ids of fake images generated by ddpm
        # if self.opt.name == 'aaf_face':
        # fake_ids_path = os.path.join(self.opt.dataroot, 'train', 'fake_ids.json')
        # if os.path.exists(fake_ids_path) and os.path.isfile(fake_ids_path):
        #     # '/chenyongfeng/FedST/diffusion_model/Palette-Image-to-Image-Diffusion-Models-main/fake_ages.json'
        #     if self.opt.federated_algorithm in ['fedddpm', 'fedst_separate', 'fedst_join']:
        #         with open(fake_ids_path, 'r', encoding='utf-8') as f:
        #             self.fake_dict = json.load(f)
        #             print("fake_dict has loaded...")
        # auto_get_fake_ids_in_dir
        if self.opt.__dict__.get('fake_dirname') and self.opt.fake_dirname is not None:
            fake_dir_path = os.path.join(self.opt.dataroot,'train', self.opt.fake_dirname)
            dirList = os.listdir(fake_dir_path)
            count = 0
            for dirname in dirList:
                if '_' in dirname:
                    count+=1
                    origin_style, fake_style = dirname.split('_')
                    if self.fake_dict.get(origin_style) is None:
                        self.fake_dict[origin_style] = []
                    self.fake_dict[origin_style].append(fake_style)
            if count == 0:
                raise Exception(f"Fake ids not found in {fake_dir_path}")
            # print(f"fake_dict={self.fake_dict}")








    def __getitem__(self, index):
        if self.opt.federated_algorithm == 'fedddpm':
            img_path = self.image_paths[index]
            label_path = self.label_paths[index]
            img = getImg(img_path, self.input_nc)
            if self.opt.name == 'face':
                client_num = str(img_path.split('/')[-2])
                class_choice = ["0", "1"]
                fake_img = getImg(img_path.replace("real_image/" + client_num,
                                                   "fake_image_join/" + client_num + '_' + choice(class_choice)),
                                  self.input_nc)
            elif self.opt.name == 'aaf_face':
                true_age = str(img_path.split('/')[-2])
                fake_ids = self.fake_dict[str(true_age)]  # read fake face images from fake_ids.json
                # select fake image of other styles randomly  eg: './dataset/AAF_Face/train/fake_image/37_77/05079A39.png'
                fake_image_path = img_path.replace("real_image/" + true_age,
                                                   f"{self.opt.fake_dirname}/" + true_age + '_' + str(
                                                       choice(fake_ids)))
                # print('Use fake image: ', fake_image_path)
                fake_img = getImg(fake_image_path, self.input_nc)
            else:
                if self.opt.model_average:  # Obtain fake images generated by aggregation models
                    fake_img = getImg(img_path.replace("real_image", "fake_image_average"), self.input_nc)
                else:
                    fake_img = getImg(img_path.replace("real_image", "fake_image_join"), self.input_nc)
            try:
                label = getImg(label_path)
            except:
                pass

            class_ = torch.from_numpy(np.array(img_path.split('/')[-2]).astype(np.float32))

            img = img.resize((self.opt.loadSize, self.opt.loadSize))
            fake_img = fake_img.resize((self.opt.loadSize, self.opt.loadSize))
            label = label.resize((self.opt.loadSize, self.opt.loadSize), resample=Image.NEAREST)
            # fake_label = fake_label.resize((self.opt.loadSize, self.opt.loadSize), resample=Image.NEAREST)

            if self.transform is not None:
                img = self.transform(img)
                fake_img = self.transform(fake_img)
            else:
                img = tr.ToTensor()(img)
                fake_img = tr.ToTensor()(fake_img)
            inst_tensor = feat_tensor = 0
            if np.max(label) > 125:
                label = tr.ToTensor()(np.array(label).astype(np.float)).type(torch.float32) / 255
                # fake_label = tr.ToTensor()(np.array(fake_label).astype(np.float)).type(torch.float32) / 255
            else:
                label = tr.ToTensor()(np.array(label).astype(np.float)).type(torch.float32)
                # fake_label = tr.ToTensor()(np.array(fake_label).astype(np.float)).type(torch.float32)

            # 'fake_image': fake_img, 'fake_label':fake_label,

            return {'image': img, 'fake_image': fake_img, 'label': label, 'inst': inst_tensor, 'class': class_,
                    'feat': feat_tensor, 'path': img_path}

        else:
            img_path = self.image_paths[index]
            img = getImg(img_path, self.input_nc)
            resize_img = getImg(img_path, 3)
            try:
                label = getImg(self.label_paths[index])
                cond_image = getImg(self.label_paths[index], 3)
            except:
                pass

            class_ = torch.from_numpy(np.array(img_path.split('/')[-2]).astype(np.float32))

            img = img.resize((self.opt.loadSize, self.opt.loadSize))
            resize_img = resize_img.resize((256, 256))
            cond_image = np.array(cond_image.resize((256, 256), resample=Image.NEAREST))
            if self.opt.name == 'face':
                cond_image = cond_image.astype(np.float)
                cond_image = (cond_image * 255 / 18).astype(np.uint8)
                cond_image = self.transform(cond_image).type(torch.float32)
            else:
                if np.max(cond_image) > 125:
                    cond_image = self.transform(cond_image)
                else:
                    cond_image = self.transform(cond_image * 255)

            label = label.resize((self.opt.loadSize, self.opt.loadSize), resample=Image.NEAREST)

            if self.transform is not None:
                img = self.transform(img)
                resize_img = self.transform(resize_img)
            else:
                img = tr.ToTensor()(img)
            inst_tensor = feat_tensor = 0
            if np.max(label) > 125:
                label = tr.ToTensor()(np.array(label).astype(np.float)).type(torch.float32) / 255
            else:
                label = tr.ToTensor()(np.array(label).astype(np.float)).type(torch.float32)

            if self.opt.model == 'fedst_ddpm':
                return {'image': img, 'label': label, 'resize_img': resize_img, 'cond_image': cond_image,
                        'inst': inst_tensor, 'class': class_, 'feat': feat_tensor,
                        'path': img_path}
            else:
                return {'image': img, 'label': label, 'inst': inst_tensor, 'class': class_, 'feat': feat_tensor,
                        'path': img_path}

    def __len__(self):

        if self.mix:
            length = len(self.image_paths)
        else:
            length = len(self.image_paths_real)
        return length


def getImg(img_path, input_nc=1):
    if input_nc == 3:
        img = Image.open(img_path).convert('RGB')
    else:
        img = Image.open(img_path).convert('L')
    return img


def _get_coutour_sample(y_true):
    disc_mask = np.expand_dims(y_true[..., 0], axis=2)

    disc_erosion = ndimage.binary_erosion(disc_mask[..., 0], iterations=1).astype(disc_mask.dtype)
    disc_dilation = ndimage.binary_dilation(disc_mask[..., 0], iterations=5).astype(disc_mask.dtype)
    disc_contour = np.expand_dims(disc_mask[..., 0] - disc_erosion, axis=2)
    disc_bg = np.expand_dims(disc_dilation - disc_mask[..., 0], axis=2)
    cup_mask = np.expand_dims(y_true[..., 1], axis=2)

    cup_erosion = ndimage.binary_erosion(cup_mask[..., 0], iterations=1).astype(cup_mask.dtype)
    cup_dilation = ndimage.binary_dilation(cup_mask[..., 0], iterations=5).astype(cup_mask.dtype)
    cup_contour = np.expand_dims(cup_mask[..., 0] - cup_erosion, axis=2)
    cup_bg = np.expand_dims(cup_dilation - cup_mask[..., 0], axis=2)

    return [disc_contour.transpose(2, 0, 1), disc_bg.transpose(2, 0, 1), cup_contour.transpose(2, 0, 1),
            cup_bg.transpose(2, 0, 1)]


def extract_amp_spectrum(img_np):
    # trg_img is of dimention CxHxW (C = 3 for RGB image and 1 for slice)

    fft = np.fft.fft2(img_np, axes=(-2, -1))
    amp_np, pha_np = np.abs(fft), np.angle(fft)

    return amp_np


def low_freq_mutate_np(amp_src, amp_trg, L=0.1):
    a_src = np.fft.fftshift(amp_src, axes=(-2, -1))
    a_trg = np.fft.fftshift(amp_trg, axes=(-2, -1))

    _, h, w = a_src.shape
    b = (np.floor(np.amin((h, w)) * L)).astype(int)
    c_h = np.floor(h / 2.0).astype(int)
    c_w = np.floor(w / 2.0).astype(int)
    # print (b)
    h1 = c_h - b
    h2 = c_h + b + 1
    w1 = c_w - b
    w2 = c_w + b + 1

    ratio = random.randint(1, 10) / 10

    a_src[:, h1:h2, w1:w2] = a_trg[:, h1:h2, w1:w2]
    # a_src[:,h1:h2,w1:w2] = a_src[:,h1:h2,w1:w2] * ratio + a_trg[:,h1:h2,w1:w2] * (1- ratio)
    # a_src[:,h1:h2,w1:w2] = a_trg[:,h1:h2,w1:w2]
    a_src = np.fft.ifftshift(a_src, axes=(-2, -1))
    # a_trg[:,h1:h2,w1:w2] = a_src[:,h1:h2,w1:w2]
    # a_trg = np.fft.ifftshift( a_trg, axes=(-2, -1) )
    return a_src


def source_to_target_freq(src_img, amp_trg, L=0.1):
    # exchange magnitude
    # input: src_img, trg_img
    src_img = src_img.transpose((2, 0, 1))
    src_img_np = src_img  # .cpu().numpy()
    fft_src_np = np.fft.fft2(src_img_np, axes=(-2, -1))

    # extract amplitude and phase of both ffts
    amp_src, pha_src = np.abs(fft_src_np), np.angle(fft_src_np)

    # mutate the amplitude part of source with target
    amp_src_ = low_freq_mutate_np(amp_src, amp_trg, L=L)

    # mutated fft of source
    fft_src_ = amp_src_ * np.exp(1j * pha_src)

    # get the mutated image
    src_in_trg = np.fft.ifft2(fft_src_, axes=(-2, -1))
    src_in_trg = np.real(src_in_trg)

    return src_in_trg.transpose(1, 2, 0)
